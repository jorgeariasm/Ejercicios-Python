{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1575845",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; text-align:right;\">22.503 · Programación para la ciencia de datos</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grado en Ciencia de Datos Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0e2c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Programación para la ciencia de datos - PEC1\n",
    "============================\n",
    "\n",
    "En este Notebook encontraréis un conjunto de ejercicios que conforman la segunda actividad de evaluación continua (PAC) de la asignatura.\n",
    "\n",
    "Para cada ejercicio, tened en cuenta que:  \n",
    "\n",
    "* **Es necesario incluir comentarios** de vuestro código, que expliquen cómo ha implementado la solución del problema planteado.  \n",
    "* **Es imprescindible** citar las referencias consultadas para realizar la actividad. Se valorará que el código proporcionado solucione el problema propuesto y también la calidad del código (comentarios, legibilidad, claridad, uso de las estructuras de datos adecuadas, buena nomenclatura de las variables y funciones, seguimiento del PEP8, etc. ).\n",
    "\n",
    "Vereis que cada una de las actividades tiene asociada una puntuación, que indica el peso que tiene la actividad sobre la nota de la PAC. \n",
    "\n",
    "Además, todas las actividades tienen una etiqueta, que indica los recursos necesarios para llevarla a cabo. Hay tres posibles etiquetas:\n",
    "* <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span>   **Sólo materiales**: las herramientas necesarias para realizar la actividad se pueden encontrar en los materiales de la asignatura (consideraremos también los materiales de la asignatura Fundamentos de Programación, así como las lecturas obligatorias de material externo que se indican en los notebooks).  \n",
    "* <span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span>**Consulta externa guiada**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, pero el enunciado contiene indicaciones de dónde o cómo encontrar la información adicional necesaria para resolver la actividad.  \n",
    "* <span style=\"font-family: Courier New; background-color: #f2ae72; color: #000000; padding: 3px; \">EI</span>**Consulta externa independiente**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, y el enunciado puede no incluir la descripción de dónde o cómo encontrar esta información adicional. Será necesario que el estudiante busque esta información utilizando los recursos que se han explicado en la asignatura.\n",
    "\n",
    "Es importante notar que estas etiquetas no indican el nivel de dificultad del ejercicio, sino únicamente la necesidad de consulta de documentación externa para su resolución. Además, recuerde que las**etiquetas son informativas**, pero puede consultar referencias externas siempre que lo desee (aunque no se indique explícitamente) o puede que pueda realizar una actividad sin consultar ningún tipo de documentación. Por ejemplo, para resolver una actividad que sólo requiera los materiales de la asignatura, puede consultar referencias externas si se desea, ya sea tanto para ayudar en la resolución como para ampliar conocimientos!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Antes de empezar\n",
    "\n",
    "Leed atentamente los parágrafos que siguen, relacionados con la originalidad en las actividades, antes de empezar a trabajar en la PEC. Si os surge cualquier duda dirigiros al profesor colaborador de la asignatura antes de continuar con la actividad.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> La falta de originalidad se produce cuando en una actividad aparece contenido que no ha sido elaborado de forma individual por el estudiante y no se referencia adecuadamente su origen. O bien cuando, aunque el contenido externo esté referenciado, este es tan extenso que no es posible considerar al estudiante el autor o autora de la actividad. \n",
    "<br /><br />\n",
    "Así, algunos ejemplos de comportamientos inadecuados debido a falta de originalidad son:\n",
    "<ol>\n",
    "    <li>Crear la solución de un ejercicio de la PEC en colaboración entre diversos estudiantes.</li>\n",
    "    <li>Incluir un ejercicio de la PEC que utiliza código encontrado en internet sin citar la fuente.</li>\n",
    "    <li>Compartir vuestra solución de la PEC con otros estudiantes de la asignatura.</li>\n",
    "    </ol>\n",
    "</div>\n",
    "\n",
    "## Instrucciones de entrega\n",
    "\n",
    "Para proceder a la entrega de la actividad es necesario realizar los siguientes pasos:\n",
    "\n",
    "1. Comprobad que el notebook se ejecuta correctamente en la máquina virtual. Es importante que antes de entregar vuestra PEC os aseguréis que la versión final del código ejecuta correctamente en su totalidad. Para ello, se recomienda hacer una ejecución completa desde cero del notebook haciendo click en *Kernel&gt; Restart & Run All* y comprobando que todas las celdas del notebook se ejecutan correctamente.\n",
    "2. Activad las alertas de estilo y comprobad que el código sigue las convenciones de estilo de Python. Si es necesario, modificad el código para adecuarlo a dichas convenciones de estilo.\n",
    "3. Confirmad que sois los autores únicos de la PEC y que esta incluye todas las citas a recursos externos que se hayan utilizado para elaborarla. Con el fin de confirmar que sois los autores únicos de la actividad, añadid vuestro nombre completo en la celda siguiente.\n",
    "4. Entregad el notebook correspondiente a la resolución de la PEC a través del Registro de Evaluación Continua del aula. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afaddc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">Yo, *Nombre y Apellidos*, confirmo que he elaborado de forma individual todas las actividades resueltas en esta PEC y que he incluido las citas a todas las fuentes externas que he utilizado para resolver las actividades. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c454e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea0e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activamos las alertas de estilo\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42367960",
   "metadata": {},
   "source": [
    "## Type hint\n",
    "\n",
    "Os recomendamos resolver esta PEC usando type hints. Podemos entender los type hints de Python como una solución formal para indicar estéticamente el tipo de valor dentro del código Python. Os recomendamos la visualización del siguiente [vídeo](https://www.youtube.com/watch?v=j0dy8Q9VIPk) para una introducción a los type hints en Python, y para entender por qué son interesantes. \n",
    "\n",
    "**El uso de type hints en la resolución de la PEC se bonificará con 0.25 puntos adicionales (para obtener toda la puntuación adicional, hay que implementar los type hints de todas las funciones implementadas en la PEC). No es necesario que utilicéis los type hints en todas las variables sino sólo en los encabezados de las funciones**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2db40d",
   "metadata": {},
   "source": [
    "##  Enunciado\n",
    "Los siguientes ejercicios se realizarán utlilizando el dataset cat_metadata_11_21.csv proporcionado juntamente con la PEC, y que contiene información sobre los post de un periódico. Cada fila representa un post (*postid*: identificador del post que ha publicado cierto usuario) realizado por el usuario con nombre de usuario *communityname*. *timestamps* nos indica la fecha en la que se ha realizado el post.\n",
    "\n",
    "Los campos del dataset son los siguientes:\n",
    "\n",
    "\n",
    "   - postid: identificador del post\n",
    "   - parentid: si un comentario es una respuesta (*reply*) a otro comentario, este campo nos indica a qué post estamors respondiendo\n",
    "   - communityname: nombre de usuario que ha realizado el post\n",
    "   - communityidentityid: identificador de usuario que ha realizado el post\n",
    "   - timestamps: feche en la que se ha realizado el post\n",
    "   - followers: cuántos seguidores tiene el usuario que ha realizado el post\n",
    "   - ratings_pos: cuántos usuarios han puntuado positivamente el post\n",
    "   - ratings_neg: cuántos usuarios han puntuado negativamente el post\n",
    "   - articleid: identificador del artículo sobre el que se ha publicado el post\n",
    "\n",
    "\n",
    "**IMPORTANTE:** La carga del dataset se debe hacer usando **rutas relativas**, tenéis que cargar el fichero teniendo en cuenta que trabajáis (vuestro notebook se encuentra) en una carpeta que contiene la carpeta *data* y el archivo de datos correspondiente.\n",
    "\n",
    "\n",
    "Sólo tenéis que cargar el fichero una sola vez en el primer ejercicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2d435",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Cargad el dataset de forma que obtengáis un objecto de tipo dataframe.\n",
    "\n",
    "Una vez cargado el dataset aplicaremos las siguientes modificaciones:\n",
    "\n",
    "1. Mostrad cuantos nans tenemos por columns\n",
    "2. Eliminad todas las filas que contengan valores nulos (nan) en las columnas: 'communityname' y 'communityidentityid'\n",
    "3. Eliminad filas duplicadas teniendo en cuenta la variable *postid*, es decir, si tenemos una fila con el mismo *postid* en este caso nos quedaremos con sólo una de las filas y no con las dos (o méas). Podéis comprobar si el resto de columnas de dos filas con el mismo *postid* son iguales.\n",
    "4. Convertid la columna *timestamps* en formato datetime donde tengamos la fecha en formato: año-mes-día\n",
    "\n",
    "Ahora queremos saber,\n",
    "\n",
    "5. Cuantos nombres de usuarios (diferentes) tenemos una vez hechas las modificaciones pedidas anteriormente? Aseguraros que este número corresponde al mismo de *communityidentityid* diferentes.\n",
    "\n",
    "\n",
    "Pista 1: Recordad qude podéis utilizar librerías como 'pandas' para cargar el conjunto de datos de forma sencilla y obtener un dataframe.\n",
    "\n",
    "Pista 2: El type hint de un dataframe es pd.DataFrame\n",
    "\n",
    "**Todos los ejercicios se tienen que resolver a partir del dataframe obtenido al finalizar este ejercicio y no cargarlo cada vez que se deba utilizar.**\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(2 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bac44",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85daaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0999bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>communityidentityid</th>\n",
       "      <th>communityname</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>followers</th>\n",
       "      <th>ratings_pos</th>\n",
       "      <th>ratings_neg</th>\n",
       "      <th>articleid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081262038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693393.0</td>\n",
       "      <td>Verrückter Hodenkobold</td>\n",
       "      <td>1636112262</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000090440224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081122567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702139.0</td>\n",
       "      <td>abracadabraham</td>\n",
       "      <td>1635938358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1081112234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499562.0</td>\n",
       "      <td>betterknower</td>\n",
       "      <td>1635929158</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081116895</td>\n",
       "      <td>1.081112e+09</td>\n",
       "      <td>175387.0</td>\n",
       "      <td>Otto Maximalverbraucher</td>\n",
       "      <td>1635933163</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081103974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91850.0</td>\n",
       "      <td>Heinz Anderle</td>\n",
       "      <td>1635919081</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       postid      parentid  communityidentityid            communityname  \\\n",
       "0  1081262038           NaN             693393.0   Verrückter Hodenkobold   \n",
       "1  1081122567           NaN             702139.0           abracadabraham   \n",
       "2  1081112234           NaN             499562.0             betterknower   \n",
       "3  1081116895  1.081112e+09             175387.0  Otto Maximalverbraucher   \n",
       "4  1081103974           NaN              91850.0            Heinz Anderle   \n",
       "\n",
       "   timestamps  followers  ratings_pos  ratings_neg      articleid  \n",
       "0  1636112262        3.0            0            0  2000090440224  \n",
       "1  1635938358        1.0            0            0  2000119861590  \n",
       "2  1635929158        9.0            2            0  2000119861590  \n",
       "3  1635933163       27.0            0            0  2000119861590  \n",
       "4  1635919081      169.0            0            0  2000119861590  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data_path = 'data/cat_metadata_11_21.csv'\n",
    "\n",
    "df = pd.read_csv(data_path, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfb9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nan values per column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "postid                      0\n",
       "parentid               296428\n",
       "communityidentityid     49971\n",
       "communityname           49971\n",
       "timestamps                  0\n",
       "followers               49971\n",
       "ratings_pos                 0\n",
       "ratings_neg                 0\n",
       "articleid                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1\n",
    "print('number of nan values per column')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d817adec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postid                      0\n",
       "parentid               283431\n",
       "communityidentityid         0\n",
       "communityname               0\n",
       "timestamps                  0\n",
       "followers                   0\n",
       "ratings_pos                 0\n",
       "ratings_neg                 0\n",
       "articleid                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 remove nan on communityidentityid\n",
    "df = df[df['communityidentityid'].notna()]\n",
    "df = df[df['communityname'].notna()]\n",
    "df.isna().sum()  # check no nan values on communityidentityid and communityname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530d77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "# remove duplicates\n",
    "df = df.drop_duplicates(subset=['postid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b29fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4\n",
    "# convert timnestamps to date format (YYYY-mm-dd)\n",
    "df['date'] = pd.to_datetime(df['timestamps'], unit='s').dt.date\n",
    "# df['date1'] = pd.to_datetime(df['timestamps'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b07d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:80: E501 line too long (82 > 79 characters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users (bt communityidentyid) 30798\n",
      "Unique users (bt communityname) 30798\n"
     ]
    }
   ],
   "source": [
    "# 1.5\n",
    "print('Unique users (bt communityidentyid)', len(df.communityidentityid.unique()))\n",
    "print('Unique users (bt communityname)', len(df.communityname.unique()))\n",
    "assert len(df.communityidentityid.unique()) == len(df.communityname.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184e1d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>communityidentityid</th>\n",
       "      <th>communityname</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>followers</th>\n",
       "      <th>ratings_pos</th>\n",
       "      <th>ratings_neg</th>\n",
       "      <th>articleid</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081262038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693393.0</td>\n",
       "      <td>Verrückter Hodenkobold</td>\n",
       "      <td>1636112262</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000090440224</td>\n",
       "      <td>2021-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081122567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702139.0</td>\n",
       "      <td>abracadabraham</td>\n",
       "      <td>1635938358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1081112234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499562.0</td>\n",
       "      <td>betterknower</td>\n",
       "      <td>1635929158</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081116895</td>\n",
       "      <td>1.081112e+09</td>\n",
       "      <td>175387.0</td>\n",
       "      <td>Otto Maximalverbraucher</td>\n",
       "      <td>1635933163</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081103974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91850.0</td>\n",
       "      <td>Heinz Anderle</td>\n",
       "      <td>1635919081</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       postid      parentid  communityidentityid            communityname  \\\n",
       "0  1081262038           NaN             693393.0   Verrückter Hodenkobold   \n",
       "1  1081122567           NaN             702139.0           abracadabraham   \n",
       "2  1081112234           NaN             499562.0             betterknower   \n",
       "3  1081116895  1.081112e+09             175387.0  Otto Maximalverbraucher   \n",
       "4  1081103974           NaN              91850.0            Heinz Anderle   \n",
       "\n",
       "   timestamps  followers  ratings_pos  ratings_neg      articleid        date  \n",
       "0  1636112262        3.0            0            0  2000090440224  2021-11-05  \n",
       "1  1635938358        1.0            0            0  2000119861590  2021-11-03  \n",
       "2  1635929158        9.0            2            0  2000119861590  2021-11-03  \n",
       "3  1635933163       27.0            0            0  2000119861590  2021-11-03  \n",
       "4  1635919081      169.0            0            0  2000119861590  2021-11-03  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6718043",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65f05b",
   "metadata": {},
   "source": [
    "2.1 Cread un diccionario usando Dictionary Comprehensions tal que:\n",
    "\n",
    "   * Sus claves correspondan al nombre de usuario (*communityname*)  \n",
    "   * Sus valores correspondan a cuántos posts ha realizado el usuario.\n",
    "\n",
    "2.2 Mostrad las 10 primeras entradas del diccionario (clave y valor) una vez lo hemos ordenado según el número de posts (de mayor a menor)\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1 punto)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7891a2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ef0fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:29: E231 missing whitespace after ','\n",
      "1:80: E501 line too long (88 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "dict_names = {key: v for key,v in df.groupby('communityname').count()['postid'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f1e489c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lexic', 2030),\n",
       " ('Götz-48', 1828),\n",
       " ('Franz Weber74', 1642),\n",
       " ('bloody-nine', 1631),\n",
       " ('sellysc', 1591),\n",
       " ('Hortensia die Erste', 1519),\n",
       " ('Amparezeptor', 1440),\n",
       " ('yoghurtinator', 1419),\n",
       " ('gmiatlich ...', 1418),\n",
       " ('Wehklagerin', 1410)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:43: W291 trailing whitespace\n"
     ]
    }
   ],
   "source": [
    "# Show sorted by values (top values first) \n",
    "sorted(dict_names.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c50a9",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "3.1 Cread una función tal que tenga como parámetros de entrada:\n",
    "* la estructura de datos (dataframe obtenido en el Ejercicio 1)\n",
    "* nombre usuario\n",
    "* nombre de la columna a tratar (*col*), que tendrá por defecto el valor *'date'*. Esta columna siempre contendrá fechas pero tenemos que pensar que puede que no siempre el nombre de la columna a tratar será *'date'*\n",
    "\n",
    "La función nos retornará un **entero** que indique el número máximo de días que un usuario ha estado sin postear.\n",
    "\n",
    "3.2 Probad vuestra función para el usuario *'lexic'* y mostrad el resultado por pantalla debidamente formateado.\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1.5 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75227e2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfda57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:64: E225 missing whitespace around operator\n",
      "3:80: E501 line too long (107 > 79 characters)\n",
      "10:1: W293 blank line contains whitespace\n",
      "13:14: W291 trailing whitespace\n",
      "17:30: E225 missing whitespace around operator\n",
      "21:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "def max_diff_user_post(df: pd.DataFrame, user: str, col='date')-> int:\n",
    "    r\"\"\"\n",
    "    This function given a dataframe, user and column of datetime compute max number of days without posting\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "    user: str\n",
    "        User name for filtering\n",
    "    col: datetime column of df\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    max_days: \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    aux = df[df.communityname==user]\n",
    "    aux = aux.sort_values(col)\n",
    "    max_days = max(aux[col].diff().iloc[1:]).days\n",
    "    return max_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27285982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of days without posting of the user with more posts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 'lexic'\n",
    "print('Max number of days without posting of the user with more posts:')\n",
    "max_diff_user_post(df, user, col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af121dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>communityidentityid</th>\n",
       "      <th>communityname</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>followers</th>\n",
       "      <th>ratings_pos</th>\n",
       "      <th>ratings_neg</th>\n",
       "      <th>articleid</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081262038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693393.0</td>\n",
       "      <td>Verrückter Hodenkobold</td>\n",
       "      <td>1636112262</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000090440224</td>\n",
       "      <td>2021-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081122567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702139.0</td>\n",
       "      <td>abracadabraham</td>\n",
       "      <td>1635938358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1081112234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499562.0</td>\n",
       "      <td>betterknower</td>\n",
       "      <td>1635929158</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081116895</td>\n",
       "      <td>1.081112e+09</td>\n",
       "      <td>175387.0</td>\n",
       "      <td>Otto Maximalverbraucher</td>\n",
       "      <td>1635933163</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081103974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91850.0</td>\n",
       "      <td>Heinz Anderle</td>\n",
       "      <td>1635919081</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000119861590</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       postid      parentid  communityidentityid            communityname  \\\n",
       "0  1081262038           NaN             693393.0   Verrückter Hodenkobold   \n",
       "1  1081122567           NaN             702139.0           abracadabraham   \n",
       "2  1081112234           NaN             499562.0             betterknower   \n",
       "3  1081116895  1.081112e+09             175387.0  Otto Maximalverbraucher   \n",
       "4  1081103974           NaN              91850.0            Heinz Anderle   \n",
       "\n",
       "   timestamps  followers  ratings_pos  ratings_neg      articleid        date  \n",
       "0  1636112262        3.0            0            0  2000090440224  2021-11-05  \n",
       "1  1635938358        1.0            0            0  2000119861590  2021-11-03  \n",
       "2  1635929158        9.0            2            0  2000119861590  2021-11-03  \n",
       "3  1635933163       27.0            0            0  2000119861590  2021-11-03  \n",
       "4  1635919081      169.0            0            0  2000119861590  2021-11-03  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89f592",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "Os pedimos lo siguiente:\n",
    "\n",
    "4.1 Cread una lista con los nombre de usuarios sin repeticiones\n",
    "\n",
    "4.2 Ordenadla (alfabéticamente, el orden establecido por Python es ja suficidente) y mostrad los 10 primeros valores.\n",
    "\n",
    "4.3 Cread un diccionario (se valorará el uso de Dict comprenhension) tal que:\n",
    "\n",
    "   * Las claves correspondan al nombre de usuario\n",
    "    \n",
    "   * Los valores correspondan al número de palabras que contiene el nombre de usuario. Consideramos que una palabra viene definida si hay un espacio entre caracteres.\n",
    "   \n",
    " Ejemplos: 'hola-adeu' (tiene una palabra), 'hola adeu' (tiene dos palabras), '!!-hola' (tiene una palabra).\n",
    " \n",
    "4.4 Del apartado anterior mostrad debidamente formatado cuál es el nombre de usuario que tiene un número mayor de palabras y cuantas palabres tiene.\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1.5 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d6295",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855bdd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!!?', '!&$/\"(&%\"!', '!+!=?', '!EswerdeLicht!', '!Yellow Submarine!', '!commentator!', '!integralthinking!', '# Rauber-Hotzenplotz', '#####', '##^^^^°°^^^^##']\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "list_names = list(set(df.communityname))\n",
    "print(sorted(list_names)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b85f8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "dict_count_words = {user: len(user.split(' ')) for user in list_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9cdbb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (88 > 79 characters)\n",
      "2:80: E501 line too long (107 > 79 characters)\n",
      "2:107: E502 the backslash is redundant between brackets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El nombre de usuario formado por más palabras es el siguiente: Warum seid ihr so blau? Weil wir saufen wie die Sau\n",
      " y está formado por 11 palabras\n"
     ]
    }
   ],
   "source": [
    "username_most_words = sorted(dict_count_words.items(), key=lambda x: x[1], reverse=True)\n",
    "print('El nombre de usuario formado por más palabras es el siguiente: {}\\n y está formado por {} palabras'\\\n",
    "      .format(username_most_words[0][0], username_most_words[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e23dff",
   "metadata": {},
   "source": [
    "## Ejericio 5\n",
    "En este ejericio practicaremos expresiones regulares, para ello os pedimos:\n",
    "\n",
    "5.1 Encontrad todos los usuarios tal que su nombre de usuario tenga como mínimo una vez un conjunto de caracteres dividido por el símbolo '-'. \n",
    "Por ejemplo: hola-adeu, !!-100, df---, hola hola-adeu adeu\n",
    "\n",
    "   a) Muestra por pantalla cuántos de este tipos de usuarios hemos encontrado\n",
    "   \n",
    "   b) Muestra el porcentaje (con sólo dos decimales) que representa este grupo de usuarios del total\n",
    "   \n",
    "   c) Muestra por pantalla los últimos 10 nombre de usuarios ordenados alfabéticamente (orden por defecto de Python)\n",
    "   \n",
    "5.2 Encuentra todos los usuarios tal que su nombre de usuario tenga dos palabras que contengan sólo letras, sin caracteres extraños ni números (mayúsculas o minúsculas). Por ejemplo:'hola hola', 'HolA holA'\n",
    "\n",
    "   a) Muestra por pantalla cuántos de este tipos de usuarios hemos encontrado\n",
    "   \n",
    "   b) Muestra el porcentaje (con sólo dos decimales) que representa este grupo de usuarios del total\n",
    "   \n",
    "   c) Muestra por pantalla los últimos 10 nombre de usuarios ordenados alfabéticamente (orden por defecto de Python)\n",
    "   \n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1.5 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be00e7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691d7e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 688 users with -\n",
      "Users with - represents 2.23% of the users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x-ray61',\n",
       " 'yolo-burger',\n",
       " 'ypso-j-neb',\n",
       " 'zFuaß-Geh-dicht',\n",
       " 'zwo-r-pi',\n",
       " '§-§',\n",
       " '°°--°°',\n",
       " 'µ-sam',\n",
       " 'ÖVP-Erwachsenenvertretung',\n",
       " 'ÖVP-Spitzenkandidat Darth Sidious']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5:80: E501 line too long (98 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "# 5.1\n",
    "regex = r\"\\S*\\S-\\S*\\S\"\n",
    "users_regex = [x for x in list_names if re.search(regex, x) is not None]\n",
    "print('We have found {} users with -'.format(len(users_regex)))\n",
    "print('Users with - represents {:.2f}% of the users'.format(100*len(users_regex)/len(list_names)))\n",
    "sorted(users_regex)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a152b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Rauber-Hotzenplotz',\n",
       " '#leben-und-leben-lassen#',\n",
       " '(-.-)Zzz...',\n",
       " '(13-1)te fee',\n",
       " '*-o-* claro',\n",
       " '+-*%',\n",
       " '---!!!---',\n",
       " '----------112-----Its---Over----Now-------',\n",
       " '--r2d2--',\n",
       " '->---',\n",
       " '-J-U-N-K-Y-',\n",
       " '0-Gini-Index',\n",
       " '0815-Kommentar',\n",
       " '1-Skeptiker',\n",
       " '1474cefc-98cb-4a27-872d-5a36a0feb1fe',\n",
       " '165409aa-f55c-4bc1-87f3-a0fdc1d951da',\n",
       " '1bf-410',\n",
       " '2a39bdfa-6c42-4e5f-8a5b-6334a9730f16',\n",
       " '2b6adb12-c784-48d5-ac47-f308e51048c4',\n",
       " '310c67ee-c9aa-479a-9bf8-2b743883f182',\n",
       " '35d69f52-bed0-',\n",
       " '360492e6-1758-4bc2-aa62-620ccee8a7b6',\n",
       " '38a25e22-1be0-4e6e-9c59-2cae225909b8',\n",
       " '3c2189e0-f239-4907-b5ab-90f82ed7518e',\n",
       " '3ea8c973-e619-4000-9081-e9d7022c6023',\n",
       " '3groschen-opa',\n",
       " '42-false-flag',\n",
       " '43867ec0-f4e5-48f2-99ee-b02cd9a2ad9a',\n",
       " '55246bf0-a0cc-4023-992d-a8588041dc22',\n",
       " '5A296969-94AD-44A8-ABF9-070B1915C171',\n",
       " '5a917d2f-e29d-4d33-8902-6b2c7bde0593',\n",
       " '5ef12e67-7d89-4b36-962b-57f4d3c99031',\n",
       " '5fbbeef7-39c1-41f1-8f48-67615596fac0',\n",
       " '64cc7203-0333-4759-99b5-1354e8298903',\n",
       " '8141-48aa-bb83-',\n",
       " '8ff-6c0c-498a-ba',\n",
       " '9e197b18-6f3b-4f10-8be2-22eda5c05833',\n",
       " '= 8-b......',\n",
       " '?-?',\n",
       " 'A-2021',\n",
       " 'A-Hai',\n",
       " 'A-Hörnchen',\n",
       " 'A-L-E-X',\n",
       " 'A-RA',\n",
       " 'A-r-c-h-o-n',\n",
       " 'A.Mo.U-R.',\n",
       " 'A340-500',\n",
       " 'AE-Optimistin',\n",
       " 'Achsel-des-Boesen',\n",
       " 'Acida-2',\n",
       " 'Ahnungs-Loser',\n",
       " 'Aladdin-Sane',\n",
       " 'Alex-aus-Hohenems',\n",
       " 'Alfred Kuhdorff-Gully',\n",
       " 'Alfred-Sauce-Tatar',\n",
       " 'Alles nicht so schlimm ;-)',\n",
       " 'Alpen-Chewie67',\n",
       " 'Alpha-Wolf',\n",
       " 'Andrea Hinterberger-Welser',\n",
       " 'Andrea Navarro-Quezada',\n",
       " 'Andreas Roither-Voigt',\n",
       " 'Andreas-h',\n",
       " 'Anjin Aku-san',\n",
       " 'Anna-Maria M.',\n",
       " 'Ano-Nym92',\n",
       " 'Anti-Alles.',\n",
       " 'Anti-Anti Pro-Pro',\n",
       " 'Anti-MaßnahmenMarschall',\n",
       " 'Anti-Postmoderner',\n",
       " 'Anti-Virus',\n",
       " 'Asfinag-Pendelguru',\n",
       " 'Auc-wer',\n",
       " 'Auslands-Österreicher',\n",
       " 'Ave-eva',\n",
       " 'BB-8',\n",
       " 'BK-philo',\n",
       " 'BWL-Student Constantin Maximilian',\n",
       " 'Bahali-Batschinki',\n",
       " 'Bambi-Meat',\n",
       " 'Barbara Schneider-Resl',\n",
       " 'Bertine-Gruebel',\n",
       " 'Bhut-Jolokia Augen-Tropfia',\n",
       " 'Biedermeier-Schreck',\n",
       " 'Bitcoin-Millionär',\n",
       " 'Bob-der-Baumeister',\n",
       " 'Boba-01',\n",
       " 'Bockwurst-Boy',\n",
       " 'Breites Speck-Trumm',\n",
       " 'BubbleBlob-12',\n",
       " 'Bundesliga-Bosna Grödig',\n",
       " 'Burki-Graz',\n",
       " 'Bürgerlich-Konservativer Waldviertler',\n",
       " 'C-Leo',\n",
       " 'C-N',\n",
       " 'CC-2224',\n",
       " 'CCAA-Resident',\n",
       " 'CE-16-75-AB-85-8B',\n",
       " 'CH-AT',\n",
       " 'Captain-Harlock',\n",
       " 'Captn-G',\n",
       " 'Carmen D-Z',\n",
       " 'Charlie-Brown',\n",
       " 'Cheese-us',\n",
       " 'Chris-08',\n",
       " 'Christian Leo-Pernold',\n",
       " 'Chui A-poo',\n",
       " 'Co-Bold',\n",
       " 'CoFit-19',\n",
       " 'Community-Eve',\n",
       " 'Community-Linienrichter',\n",
       " 'Community-Mitglied',\n",
       " 'Community-Name:',\n",
       " 'Community-NameName',\n",
       " 'Community-Namen 2',\n",
       " 'Crypto-Kweis',\n",
       " 'D-AUT 0-0 nach 30 j',\n",
       " 'DDr. Dipl.-Ing. Manuel Eder',\n",
       " 'DJ-Ridu',\n",
       " 'Dageg-Er (innen) Lohnarbeit-Verweigere aus Überzeug',\n",
       " 'Daruma-San',\n",
       " 'Das ist mein Community-Name',\n",
       " 'DasistmeinCommunity-Name',\n",
       " 'Denken-Denken-Denken',\n",
       " 'Der FHA-Pate',\n",
       " 'Der Li-La-miese-Launebär',\n",
       " 'Der R-Bubenkanzler',\n",
       " 'Der Wikinger-Schiffsrabbi',\n",
       " 'Der-Bürger',\n",
       " 'Der-Kaiser-von-Mühlen',\n",
       " 'Der-Optimist',\n",
       " 'Der-Picknicker',\n",
       " 'Der-Weg-ist-das-Ziel',\n",
       " 'DerPoster-wiW(wohntinWien)',\n",
       " 'Dif-tor heh smusma',\n",
       " 'Diversity-Mensch',\n",
       " 'Doktor-Ingenieur',\n",
       " 'Don Alonso-Ildefonso',\n",
       " 'Dont-kill-the-messenger',\n",
       " 'Dontstop-Mike',\n",
       " 'Doppel-Tschek',\n",
       " 'Dora Gmeiner-Jahn',\n",
       " 'Dosenbier-Flasche',\n",
       " 'Dr.EM-Checker',\n",
       " 'Dunning-Kluger',\n",
       " 'E-K',\n",
       " 'EFSF-EinFollSchönesFest',\n",
       " 'Ebenezer-2021-11',\n",
       " 'Eddie-the-Eagle',\n",
       " 'Eduard-Barry Umlauf',\n",
       " 'Ei-Heinz',\n",
       " 'Eigene-Meinung',\n",
       " 'Ein-interessierter-Leser',\n",
       " 'Einfach-Leo',\n",
       " 'Eis-mann',\n",
       " 'El-Salato',\n",
       " 'El-Tom',\n",
       " 'Eliza-Elauter',\n",
       " 'Elland Road-LUFC',\n",
       " 'Escandal-Oso',\n",
       " 'Est-dragon',\n",
       " 'Eva-Maria Perwanger',\n",
       " 'Evaluierungs-Hofrat',\n",
       " 'Ex-Mühviadla',\n",
       " 'Ex-Østerreicher',\n",
       " 'FPÖ-Gegner',\n",
       " 'Facebook-Legastheniker',\n",
       " 'Fdl-Krt',\n",
       " 'Flex-a-loch',\n",
       " 'Flip-per',\n",
       " 'Fomalhaut-b',\n",
       " 'Fonsi_and-the_bear',\n",
       " 'Foren-Moderation',\n",
       " 'Franz-Josef Platen',\n",
       " 'Freud-Voll',\n",
       " 'Freundlicher Impf-Freund',\n",
       " 'Freya Nakamachi-47',\n",
       " 'Fritz der Kommunen-Teufel',\n",
       " 'Frog-silverlight',\n",
       " 'Frustrations-Attraktion',\n",
       " 'G-Dil',\n",
       " 'G-quadrat',\n",
       " 'Ge-menge-lage',\n",
       " 'Geh-bitte',\n",
       " 'Gehirnamputierter NC-Flüchtling',\n",
       " 'Geidorf-Städter',\n",
       " 'Gelbfuß-Regenpfeifer',\n",
       " 'Goaßmaß-3.0',\n",
       " 'Gute-Nudel-Stern',\n",
       " 'Götz-48',\n",
       " 'H.-C.Starche',\n",
       " 'Ha Tse-tung',\n",
       " 'Hakuna-matata',\n",
       " 'Hale-Bopp',\n",
       " 'Hannibal Barkas-243',\n",
       " 'Hans-Dampf',\n",
       " 'Hans-Dietrich Jansche von Hochhausen-Glocken',\n",
       " 'Happy-Expat',\n",
       " 'Harun al-Raschid',\n",
       " 'He-Man II.',\n",
       " 'Heino-Fan mit Rollator',\n",
       " 'Heinz-Rüdiger',\n",
       " 'Hekto-Pascal',\n",
       " 'Herbert H-I',\n",
       " 'Hermine Fischer-Müller',\n",
       " 'Herr Hermann Hermann-Mann',\n",
       " 'Hidalgo-Bronco',\n",
       " 'Hier der Community-Name',\n",
       " 'Hr. Dünnsch-Eist',\n",
       " 'Huup-té',\n",
       " 'I-was-jetzt-a-ned',\n",
       " 'IP-Adresse',\n",
       " 'IT-Alien',\n",
       " 'IT-Fachkraft',\n",
       " 'IT-Fuzzi',\n",
       " 'Ich lebe jetzt. Morgen kann es zu spät sein ;-)',\n",
       " 'Ich will keinen Community-Namen!',\n",
       " 'Ich wähle einen Community-Namen',\n",
       " 'Ich-nicht-Du',\n",
       " 'Ich_muss_einen_Community-Namen_haben',\n",
       " 'Im-Nachhinein-sind-alle-gescheiter',\n",
       " 'In-Medias-Res',\n",
       " 'In-sag-i',\n",
       " 'Info-rebel',\n",
       " 'Inter-/National Pressservice Distributor',\n",
       " 'Iran-news',\n",
       " 'Irgend-was',\n",
       " 'Irgendein Standard-Leser',\n",
       " 'Iron-I',\n",
       " 'JEM-berlin',\n",
       " 'JJB-Standard',\n",
       " 'Ja-Eh',\n",
       " 'James-Blond',\n",
       " 'Jan-Frederic Czatorisky',\n",
       " 'Jang-Jing',\n",
       " 'Jean-Luc',\n",
       " 'Jean-Marie Rochefort',\n",
       " 'Jim-Morisson',\n",
       " 'Jimbo 7.7.7 :-)',\n",
       " 'Jo-Jo',\n",
       " 'Joe-Fox',\n",
       " 'Johann-Alexandros',\n",
       " 'Josef-Maximilian',\n",
       " 'Ju-on',\n",
       " 'K-Punkt',\n",
       " 'Kaerntner_und_nicht-bzoe-waehler',\n",
       " 'Kanarien-Dramatik',\n",
       " 'Karate-Wotke',\n",
       " 'Karl-Heinz Dicktragichauf',\n",
       " 'Karl-Heinz1306',\n",
       " 'Karl-Hoax Grassi',\n",
       " 'Kassandra-Syndrom',\n",
       " 'Kaunitz-01',\n",
       " 'Kay-Michael Dankl',\n",
       " 'Kein-Haar-Pulli',\n",
       " 'Kell-Conerem',\n",
       " 'Keyser-Söze',\n",
       " 'Klaas-Jan',\n",
       " 'Klabauter-Dompteuse',\n",
       " 'Klara-Fall',\n",
       " 'Klaus-123x',\n",
       " 'Kombucha-Jünger',\n",
       " 'Kommentator-08-15',\n",
       " 'Kommjuniti-name',\n",
       " 'Kommt-ein-Vogerl-geflogen',\n",
       " 'Kon\\xadglo\\xadme\\xadrat-Hybris',\n",
       " 'Kot-fit 19',\n",
       " 'Krach-Bum-Ente',\n",
       " 'Kärntner-Freiheit',\n",
       " \"L'eu El-Rühb\",\n",
       " 'L-L',\n",
       " 'La-dee-da',\n",
       " 'La-ster',\n",
       " 'Lalelu-Mond',\n",
       " 'Land-Ei',\n",
       " 'Land-Oktopus',\n",
       " 'Leia-Lillét',\n",
       " 'Lemmi-Winks',\n",
       " 'Leonhard(-o) da Wien(-tschi)',\n",
       " 'Lepidoptera-1',\n",
       " 'Liebling der derStandard-Redaktion',\n",
       " 'Lisa-K.',\n",
       " 'Lizensierter Gecko-Jäger',\n",
       " 'Lou-Cypher',\n",
       " 'Lt. Counselor Worf \"Data\" LaTroy-Ryker',\n",
       " 'Lui-Vincitore Casa-Piccolo',\n",
       " 'M-A-X',\n",
       " 'M.-B.',\n",
       " 'MARK-EU',\n",
       " 'Mabeh Al-Zuq Yadeek',\n",
       " 'Madame-Chauchat',\n",
       " 'Mademyday-Kommentare-lieb-ich-sehr',\n",
       " 'Marie-Sophie',\n",
       " 'Mario-Anna',\n",
       " 'Marjory Stewart-Baxter',\n",
       " 'Master-baiter',\n",
       " 'Maximilian Klein-Großwelt',\n",
       " 'Mayer-Mayer-Ling',\n",
       " 'Mc-Gyver',\n",
       " 'Mein-Community-Name',\n",
       " 'Mein-Senf-dazu-',\n",
       " 'Mein-Ung',\n",
       " 'Meinungs-freiheit',\n",
       " 'Mene mene tekel u-parsin',\n",
       " 'Milieubedingter-Hojac oder besser Saualm-Haider?',\n",
       " 'Mitte-Rechts-Linker Nichtwähler',\n",
       " 'Mostly-Harmless',\n",
       " 'Mr-Anonym',\n",
       " 'Mr-D',\n",
       " 'Muh-kuh-lee',\n",
       " 'Mul-ti-pass!',\n",
       " 'Mut-Wut-Musikant',\n",
       " 'Muzi-Schnegge',\n",
       " 'Möchtegern-Österreicherin',\n",
       " 'N-Tupel',\n",
       " 'NCC-1701-E',\n",
       " 'NEOS-Stammwähler',\n",
       " 'Nachbarschaft-von-Cappuccetto',\n",
       " 'Nara-Sin',\n",
       " 'Nein-Doch-Oh!',\n",
       " 'Neuer-Postingname',\n",
       " 'NewNormality-Insurgent',\n",
       " 'Nexus-7',\n",
       " 'Nie wieder US-Truppen in Europa!',\n",
       " 'NoBibi 8-)',\n",
       " 'NoT-aUsGaNg gItArRe',\n",
       " 'Non-Fungible User',\n",
       " 'Nougat-Krokant',\n",
       " 'Novak-Nr-1',\n",
       " 'Nudelhaar-Katze',\n",
       " 'Nuss-Nougat',\n",
       " 'OE-MS',\n",
       " 'Ober-Lehrer',\n",
       " 'Ocr-fanat',\n",
       " 'OhneLippen-Lippenbekenner',\n",
       " 'Oida-Habara',\n",
       " 'Onkel-Bob',\n",
       " 'Online-Banker',\n",
       " 'Opt-Out',\n",
       " 'Optimistisch-pessimistischer Realist',\n",
       " 'Ortho-was',\n",
       " 'PRO-haska',\n",
       " 'Peter-Alexander Schneider',\n",
       " 'Petra-M',\n",
       " 'Physio-Alex',\n",
       " 'Pierre-Joseph Proudhon',\n",
       " 'Pik-Ass',\n",
       " 'Pink-Lady',\n",
       " 'Placebo-Einhorn',\n",
       " 'Polite-respectful',\n",
       " 'Possum-sed nolo',\n",
       " 'Post-ist-da',\n",
       " 'Proxima-Centauri',\n",
       " 'Pseudo-Nym',\n",
       " 'Quantum-Quant',\n",
       " 'Quarantäne-Däne',\n",
       " 'R-M.Z',\n",
       " 'Radler-21',\n",
       " 'Ramirez-Auron',\n",
       " 'Randlos-N',\n",
       " 'Rette-sich-wer-kann',\n",
       " 'Robin-H.',\n",
       " 'Rocker-Man',\n",
       " 'Rohr-verleger',\n",
       " 'Roman-Hammer',\n",
       " 'Rosa Winkler-Hermaden',\n",
       " 'Rudi-the-Wanderer_',\n",
       " 'Ruth Schlabbeeritzka-Pangl',\n",
       " 'S-P',\n",
       " 'S.A-S',\n",
       " 'SAB-.-.-',\n",
       " 'SLG-666',\n",
       " 'SOLUS-Studie',\n",
       " 'SPÖ-King',\n",
       " 'STANDARD-MitposterInnen',\n",
       " 'STG-86',\n",
       " 'Salz-Amt',\n",
       " 'Sancta-Simplicitas',\n",
       " 'Sara-Maria (Warum existiert dieser Name schon?)',\n",
       " 'Sc1ence-Fact-F1ct10n',\n",
       " 'Schlamm-Assel',\n",
       " 'Schlechtes Posting-Karma laut Foromat',\n",
       " 'Schluß mit der CO2-Abzocke!',\n",
       " 'Schnüffel-SNAFU',\n",
       " 'Schrödingers-Katze',\n",
       " 'Scourge-Hansi',\n",
       " 'Selber-Denken',\n",
       " 'Self-Made-Me',\n",
       " 'Seppl-04',\n",
       " 'Shai-Hulud_III',\n",
       " 'Shaolin Kung-jin',\n",
       " 'Sharru-kin',\n",
       " 'Sherlock-Homeless',\n",
       " 'Shotgun-Ronnie',\n",
       " 'Siegfried Schöch-Fitz',\n",
       " 'Sil-Via',\n",
       " 'Simon-B',\n",
       " 'Sirius09-hell',\n",
       " 'Skoops-o-tronic',\n",
       " 'SnoreFree App Anti-Schnarch Therapie',\n",
       " 'Snow-white199',\n",
       " 'So-lala',\n",
       " 'Soave-Redlich-Kwong',\n",
       " 'Soll-Bruchstelle',\n",
       " 'Sowjetischer Rauch-Absauger',\n",
       " 'Spies-Äquivalent',\n",
       " 'Spiritual-life',\n",
       " 'St.-St. Ühm',\n",
       " 'Standard-Abweichung',\n",
       " 'Standard-Besucher',\n",
       " 'Standard-Name',\n",
       " 'Standard-Troll',\n",
       " 'State-ment',\n",
       " 'Step-by-step',\n",
       " 'Stephan Reiter-Petrov',\n",
       " 'Steve-O',\n",
       " 'Stichschutz-Vollplattenrüstung',\n",
       " 'Subjektiv-Sachlich',\n",
       " 'Sugar-Ro',\n",
       " 'Super-Toaster',\n",
       " 'Süß-saurer Senf',\n",
       " 'T-Dogg808',\n",
       " 'T-One',\n",
       " 'T-P-A',\n",
       " 'TM-3',\n",
       " 'Tante-Horst',\n",
       " 'Tau-Neutrino',\n",
       " 'Test-Heribert',\n",
       " 'The Non-flying Dutchman',\n",
       " 'Theorie-Praxis',\n",
       " 'Theresa Nusnasch-Encore',\n",
       " 'Think-TS',\n",
       " 'Thomas-1220',\n",
       " 'Thomas-Wien',\n",
       " 'Tobi-Wan Kenobi',\n",
       " 'Toffy-Fee',\n",
       " 'Tom 1701-D',\n",
       " 'Tom-Horn',\n",
       " 'Toulouse-Lautrec',\n",
       " 'TreblA-91',\n",
       " 'Tritsch-Tratsch',\n",
       " 'Turtle-Express',\n",
       " 'Twain-Fan',\n",
       " 'U-Bahn Steuer',\n",
       " 'U-Schelle',\n",
       " 'UDFy-38135539',\n",
       " 'Unfreiwilliger Kanzlerfest-Mitfinanzierer',\n",
       " 'Us-Er',\n",
       " 'Uschi-Stenzel-Dürrenmatt-Buchclub',\n",
       " 'User-ID',\n",
       " 'V-creator',\n",
       " 'Vend-etta',\n",
       " 'W-T-F',\n",
       " 'Wa(h)re (Des-)Information',\n",
       " 'Wahl-Ösi',\n",
       " 'Waldgänger am Hochwald-Waldsteig im Nachsommer',\n",
       " 'Wann-wird-endlich-Sommer?',\n",
       " 'Weiß-auch-alles:)',\n",
       " 'Wende-Zeit',\n",
       " 'Wiener-im-Exil',\n",
       " 'Wienerin_:-)',\n",
       " 'Wir alle sind Triple-A',\n",
       " 'Wolf-gang',\n",
       " 'Wonder-Warthog ©',\n",
       " 'Woodoo-Känguruh',\n",
       " 'Worte-Torte',\n",
       " 'Wortspenden Repositorium (nicht-lobbyiert)',\n",
       " 'WoswasdenI-wucky',\n",
       " 'Wählen Sie Ihren Community-Namen II',\n",
       " 'Wählen Sie einen Community-Namen',\n",
       " 'Wünsch-dir-was',\n",
       " 'X-77',\n",
       " 'X-für-Nix',\n",
       " 'Xana-Marie',\n",
       " \"Z'fleiß-garnix\",\n",
       " 'Zen-Trum',\n",
       " 'Zitronen-Presse',\n",
       " 'Zwickts-mi',\n",
       " '[]--[\"\"\"|\"\"\"|\"\"\"|\"\"\"]-----',\n",
       " '[]--[\"\"\"|\"\"\"|\"\"\"|\"\"\"]------',\n",
       " '[]--[\"\"\"|\"\"\"|\"\"\"|\"\"\"|\"\"\"]-----',\n",
       " '___-----',\n",
       " 'a323c0cf-3258-42b9-ae46-ef2b197a4817',\n",
       " 'a71677f8-bfb0-40d6-99ed-396fdb7256f6',\n",
       " 'aa243952-e6de-4407-b02c-9deba2bff558',\n",
       " 'aber geh ;-)',\n",
       " 'af04404d-581b-468c-a140-3f56ac3a350a',\n",
       " 'aint-talking-just-walking',\n",
       " 'air-design',\n",
       " 'alfheinz ernst stragrasser-poully',\n",
       " 'alpha-omega',\n",
       " 'alpha-yeti',\n",
       " 'alt-heli .',\n",
       " 'am-dam-des',\n",
       " 'an-denken',\n",
       " 'and-one',\n",
       " 'antares-im-skorpion',\n",
       " 'anton-aus-tyrol',\n",
       " 'audiatur-et-altera',\n",
       " 'ba9ff83a-45aa-11ea-b77f-2e728ce88125',\n",
       " 'big-burger',\n",
       " 'bio-sport',\n",
       " 'bloody-nine',\n",
       " 'bs-bs',\n",
       " 'büro-krater',\n",
       " 'c-18',\n",
       " 'c-e-f',\n",
       " 'c-l-e-m-e-n-s',\n",
       " 'c54988b6-f0b7-49fb-acab-123139b762d6',\n",
       " 'ca400237-c81f-4203-8654-6993dbeb6064',\n",
       " 'chap-o-clack',\n",
       " 'community-name entspricht nicht den richtlinien',\n",
       " 'd-fekt',\n",
       " 'd4-4a0',\n",
       " 'd9670e59-e92e-47f3-a1e8-6ec71005a83a',\n",
       " 'dagegen-läufer',\n",
       " 'default-user',\n",
       " 'der Bundesland-aufhetzer',\n",
       " 'der-für-seine-Familie-kämpft',\n",
       " 'der-ka',\n",
       " 'der-nicht-standard',\n",
       " 'des-is-jo-oarg',\n",
       " 'die Resi-Tant Evil',\n",
       " 'die-weltmaschine',\n",
       " 'dieStandard-Leserin',\n",
       " 'dingsda-wieder-da',\n",
       " 'doc-holiday',\n",
       " 'dös-darf-net-woar-sein',\n",
       " 'e-pez',\n",
       " 'e-spider',\n",
       " 'e37f5af6-ce82-471e-9193-81b045db43b8',\n",
       " 'eh-nur-i',\n",
       " 'eh-scho-wissen',\n",
       " 'eh-wuascht',\n",
       " 'el-stefane',\n",
       " 'eleven-thirtyfour.',\n",
       " 'en-ef-elli',\n",
       " 'energie-information',\n",
       " 'ettore-77',\n",
       " 'evil-god',\n",
       " 'ex-NL',\n",
       " 'exo-politics',\n",
       " 'faules-faultier',\n",
       " 'feldwebel-colon',\n",
       " 'filo-sofie',\n",
       " 'for-ever-young',\n",
       " 'foren-sick',\n",
       " 'freddy-fux',\n",
       " 'freedom-driver',\n",
       " 'fritz-fantom',\n",
       " 'gays-come-first',\n",
       " 'genesis-block',\n",
       " 'georg-98113',\n",
       " 'get-a-life',\n",
       " 'giggedie-giggedie',\n",
       " 'giovanni-brambilla',\n",
       " 'got-it all',\n",
       " \"grep 'hirn' --ilrI schädel\",\n",
       " 'hallo-erstmal',\n",
       " 'hans-herbert',\n",
       " 'hans-hermann',\n",
       " 'happy-camper',\n",
       " 'he-is-mi-and-i-am-yu',\n",
       " 'herr-s',\n",
       " 'high-fidelity',\n",
       " 'hp-instanz',\n",
       " 'huber-franz',\n",
       " 'i-sun',\n",
       " 'i-tüpfelchen-reiter',\n",
       " 'iatro-texnis',\n",
       " 'ich bin rapid-fan',\n",
       " 'ich-bin-der-ich-bin',\n",
       " 'ich-habe-fertig',\n",
       " 'ich-schau-nur',\n",
       " 'ihr-habts-ja-keine-ahnung-und-überhaupt',\n",
       " 'info-stand',\n",
       " 'is-des-net-wurscht',\n",
       " 'its-me',\n",
       " 'ja-dann',\n",
       " 'jfk-alive',\n",
       " 'jo-fi',\n",
       " 'joachim gruber-scheikl',\n",
       " 'joe-hons',\n",
       " 'just-escapes-me',\n",
       " 'k-eater',\n",
       " 'k-girl',\n",
       " 'ka-tse',\n",
       " 'kein-meilenstein',\n",
       " 'keine-gerechtigkeit-in-at',\n",
       " 'keinfünfuhrtee-lieberbier',\n",
       " 'knock-knock',\n",
       " 'krawuzi-kapuzi',\n",
       " 'krone-leserbriefschreiber',\n",
       " 'la-ile',\n",
       " 'la-la-lama',\n",
       " 'lee-marvin',\n",
       " 'les-moyens-de-prévenir-les-enterrements-prématurés',\n",
       " 'lies-nix',\n",
       " 'lina-amelie',\n",
       " 'links-ich-rechts',\n",
       " 'loki-san',\n",
       " 'm-j',\n",
       " 'm-k-w',\n",
       " 'm-s',\n",
       " 'madmike-1968',\n",
       " 'manchmal-tuts-weh',\n",
       " 'marie-curie',\n",
       " 'mecirsch-the-cat',\n",
       " 'medium-rare',\n",
       " 'mein-senf-dazu',\n",
       " 'mike-india-alpha',\n",
       " 'mini-maus',\n",
       " 'miss-sing-link',\n",
       " 'mo-sat',\n",
       " 'mr-creosote',\n",
       " 'my-nung',\n",
       " 'mz-doktor',\n",
       " 'n--n',\n",
       " 'n0-0ne',\n",
       " 'na-servas',\n",
       " 'net-diver',\n",
       " 'nicht-ohne-worte',\n",
       " 'olinus-lini',\n",
       " 'ooe-123',\n",
       " 'p-hammer',\n",
       " 'panic-stricken chicken',\n",
       " 'paper-rich',\n",
       " 'pc-nice',\n",
       " 'peace-out',\n",
       " 'pirx-o-mat',\n",
       " 'plastic-stress',\n",
       " 'post-it!',\n",
       " 'power-cat',\n",
       " 'prohaska-8',\n",
       " 'proud-to-be-weltfremd',\n",
       " 'pu-muckl',\n",
       " 'question-mark',\n",
       " 're-play',\n",
       " 'reni-x',\n",
       " 'ri-online',\n",
       " 'rich-art',\n",
       " 'richard st-b',\n",
       " 'ross-a-tron',\n",
       " 's-g aurora',\n",
       " 'savoir-vivre',\n",
       " 'sbeb-nerzooo',\n",
       " 'schemen-fechter',\n",
       " 'schwechater-recht-hat-er',\n",
       " 'second-hand brain',\n",
       " 'see-you',\n",
       " 'senf-dazu-geberin',\n",
       " 'she-who-must-not-be-named',\n",
       " 'sixty-six',\n",
       " 'slashinger-49art',\n",
       " 'so-g',\n",
       " 'so-wie-so-ned',\n",
       " 'son-of-anarchy',\n",
       " 'sparky-corona',\n",
       " 't-storm',\n",
       " 'tagewerk-des-honigvogels',\n",
       " 'the-no-name-society',\n",
       " 'throatwobbler-mangrove',\n",
       " 'tofu-n-beer',\n",
       " 'triple-s',\n",
       " 'un-logger',\n",
       " 'urban-a',\n",
       " 'uvw-xyz',\n",
       " 'w-see',\n",
       " 'wald-4tel',\n",
       " 'warum-nicht..',\n",
       " 'weissnix-sagnix',\n",
       " 'wheelchair-warrior',\n",
       " 'why-the-face-89',\n",
       " 'wie-so',\n",
       " 'wirbel-wind',\n",
       " 'witty-sw',\n",
       " 'wonder-woman',\n",
       " 'woodpecker-spotted',\n",
       " 'world-citizen',\n",
       " 'x-ray61',\n",
       " 'yolo-burger',\n",
       " 'ypso-j-neb',\n",
       " 'zFuaß-Geh-dicht',\n",
       " 'zwo-r-pi',\n",
       " '§-§',\n",
       " '°°--°°',\n",
       " 'µ-sam',\n",
       " 'ÖVP-Erwachsenenvertretung',\n",
       " 'ÖVP-Spitzenkandidat Darth Sidious']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(users_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1fc6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2\n",
    "regex2 = r\"^[a-zA-Z]*\\s[a-zA-Z]*$\"\n",
    "users_regex2 = [x for x in list_names if re.search(regex2, x) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf16be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 4362 usersname with two words containing only letters\n",
      "It represents 14.16% of the users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A Therapie',\n",
       " 'A Wanderer',\n",
       " 'A nonymous',\n",
       " 'ABC Guy',\n",
       " 'AI Clover',\n",
       " 'AMS LER',\n",
       " 'Aaron Lopez',\n",
       " 'Abdul Alhazred',\n",
       " 'Aberer Franz',\n",
       " 'Abersaidschan Oida']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (100 > 79 characters)\n",
      "2:80: E501 line too long (89 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "print('We have found {} usersname with two words containing only letters'.format(len(users_regex2)))\n",
    "print('It represents {:.2f}% of the users'.format(100*len(users_regex2)/len(list_names)))\n",
    "sorted(users_regex2)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4105b",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "6.1 Definid una función (**el cuerpo de la cual contenga una sola expresión**) que reciba como parámetros:\n",
    "\n",
    "* La estructura de datos creada (dataframe obtenido en el Ejercicio 1)\n",
    "\n",
    "* cols: Las columnas que usaremos\n",
    "\n",
    "* topN: El número de posts que queremos que nos retorne, el valor por defecto de este parámetro será 50.\n",
    "\n",
    "\n",
    "y retornad un diccionario ordenado (OrderedDict) los elementos del cual sigan la siguiente estructura:\n",
    "\n",
    "        {\n",
    "            postid : {\n",
    "                communityname : str\n",
    "                date : datetime,\n",
    "                articleid: int,\n",
    "            }\n",
    "        }\n",
    "\n",
    "La estructura del diccionario sería: {id_1: {...}, id_2: {...}, id_N: {...}}.\n",
    "El diccionario tiene que estar ordenado por postid y tiene que contener tan solo tantos posts como le hayamos dicho en la variable topN.\n",
    "\n",
    "6.2 Comprovad que la función se ejecuta correctamente invocandola con *topN=10*.\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1.5 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a159288",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2e31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5:80: E501 line too long (92 > 79 characters)\n",
      "6:80: E501 line too long (81 > 79 characters)\n",
      "7:5: E122 continuation line missing indentation or outdented\n"
     ]
    }
   ],
   "source": [
    "# 6.1\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def create_ordered_dict(df, cols=['postid', 'date', 'communityname', 'articleid'], topN=50):\n",
    "    return df[cols].sort_values(\"postid\").head(topN).set_index(\"postid\").to_dict(\n",
    "    into=OrderedDict, orient=\"index\")\n",
    "\n",
    "# def create_ordered_dict(df, cols, topN=50):\n",
    "#     return df[cols].sort_values(\"postid\").head(topN).set_index(\"postid\").to_dict(\n",
    "#     into=OrderedDict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52fed498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1081009121,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'Berggasse',\n",
       "               'articleid': 2000130741244}),\n",
       "             (1081009148,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'UnholyMartin',\n",
       "               'articleid': 2000130808008}),\n",
       "             (1081009156,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'Bonomax',\n",
       "               'articleid': 2000130808008}),\n",
       "             (1081009185,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'Ironie',\n",
       "               'articleid': 2000130741244}),\n",
       "             (1081009208,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'bakk. noah seydl',\n",
       "               'articleid': 2000130808008}),\n",
       "             (1081009220,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'DerAllesWisser',\n",
       "               'articleid': 2000130713672}),\n",
       "             (1081009223,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'isebuki',\n",
       "               'articleid': 2000130713672}),\n",
       "             (1081009227,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'Hyperkubikwurzel',\n",
       "               'articleid': 2000130741244}),\n",
       "             (1081009232,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'Richter Di',\n",
       "               'articleid': 2000129066509}),\n",
       "             (1081009250,\n",
       "              {'date': datetime.date(2021, 11, 1),\n",
       "               'communityname': 'peak oil',\n",
       "               'articleid': 2000130741244})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.2\n",
    "create_ordered_dict(df, topN=10)\n",
    "\n",
    "# create_ordered_dict(df, ['postid', 'date', 'communityname', 'articleid'], topN=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff148fce",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "7.1 A qué estructura de datos estudiada en teoría os recuerda el ir haciendo *replies* de un post?\n",
    "Teniendo en cuenta que cuando eliminamos un *reply* siempre quitamos el último que se ha hecho. Justificad la respuesta.\n",
    "\n",
    "7.2 Simulad programando como añadiríais los siguientes comentarios con identificador 1234,15657, 4656547 , 234 donde el primer comentario es el 1234, el segundo el 234, el tercero 15657 y el cuarto 4656547. Y después eliminaremos los dos últimos.\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1 punto)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c4e8b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solució</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97e8ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:80: E501 line too long (107 > 79 characters)\n",
      "2:108: W291 trailing whitespace\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial stack  [1234, 234, 15657, 4656547]\n",
      "Remove last post  [1234, 234, 15657]\n",
      "Remove last post  [1234, 234]\n"
     ]
    }
   ],
   "source": [
    "# PILA (stack)\n",
    "# Podríamos utilitzar una pila (stack) para representar el historial de posts, ya el último post registrado \n",
    "# siempre será el primero en ser eliminado (FILO).\n",
    "pila_posts = []\n",
    "pila_posts.append(1234)\n",
    "pila_posts.append(234)\n",
    "pila_posts.append(15657)\n",
    "pila_posts.append(4656547)\n",
    "print('Initial stack ', pila_posts)\n",
    "pila_posts.pop()\n",
    "print('Remove last post ', pila_posts)\n",
    "pila_posts.pop()\n",
    "print('Remove last post ', pila_posts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
